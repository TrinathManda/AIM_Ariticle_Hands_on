{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AIM_ResNet50 in PyTorch with TPU.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "q1PwzSbg34sq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#https://analyticsindiamag.com/hands-on-guide-to-implement-resnet50-in-pytorch-with-tpu/\n",
        "\n",
        "import os\n",
        "assert os.environ['COLAB_TPU_ADDR']"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-FUm9xZnNUXV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "8287cd5e-98dd-4c7d-9830-1bfc47209ba1"
      },
      "source": [
        "TPU_Path = 'grpc://'+os.environ['COLAB_TPU_ADDR']\n",
        "print('TPU Address:', TPU_Path)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TPU Address: grpc://10.72.64.50:8470\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XzUCPn7gNUaZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "14dbd572-c453-497d-8d83-64fd23f1770a"
      },
      "source": [
        "VERSION = \"20200516\"\n",
        "!curl https://raw.githubusercontent.com/pytorch/xla/master/contrib/scripts/env-setup.py -o pytorch-xla-env-setup.py\n",
        "!python pytorch-xla-env-setup.py --version $VERSION"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  5115  100  5115    0     0  24951      0 --:--:-- --:--:-- --:--:-- 24951\n",
            "Updating... This may take around 2 minutes.\n",
            "Updating TPU runtime to pytorch-dev20200516 ...\n",
            "Collecting cloud-tpu-client\n",
            "  Downloading https://files.pythonhosted.org/packages/56/9f/7b1958c2886db06feb5de5b2c191096f9e619914b6c31fdf93999fdbbd8b/cloud_tpu_client-0.10-py3-none-any.whl\n",
            "Collecting google-api-python-client==1.8.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9a/b4/a955f393b838bc47cbb6ae4643b9d0f90333d3b4db4dc1e819f36aad18cc/google_api_python_client-1.8.0-py3-none-any.whl (57kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 2.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: oauth2client in /usr/local/lib/python3.6/dist-packages (from cloud-tpu-client) (4.1.3)\n",
            "Requirement already satisfied: google-auth-httplib2>=0.0.3 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client==1.8.0->cloud-tpu-client) (0.0.4)\n",
            "Requirement already satisfied: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client==1.8.0->cloud-tpu-client) (3.0.1)\n",
            "Requirement already satisfied: google-auth>=1.4.1 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client==1.8.0->cloud-tpu-client) (1.17.2)\n",
            "Requirement already satisfied: six<2dev,>=1.6.1 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client==1.8.0->cloud-tpu-client) (1.15.0)\n",
            "Requirement already satisfied: google-api-core<2dev,>=1.13.0 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client==1.8.0->cloud-tpu-client) (1.16.0)\n",
            "Requirement already satisfied: httplib2<1dev,>=0.9.2 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client==1.8.0->cloud-tpu-client) (0.17.4)\n",
            "Requirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python3.6/dist-packages (from oauth2client->cloud-tpu-client) (0.4.8)\n",
            "Requirement already satisfied: rsa>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from oauth2client->cloud-tpu-client) (4.6)\n",
            "Requirement already satisfied: pyasn1-modules>=0.0.5 in /usr/local/lib/python3.6/dist-packages (from oauth2client->cloud-tpu-client) (0.2.8)\n",
            "Requirement already satisfied: setuptools>=40.3.0 in /usr/local/lib/python3.6/dist-packages (from google-auth>=1.4.1->google-api-python-client==1.8.0->cloud-tpu-client) (50.3.0)\n",
            "Uninstalling torch-1.6.0+cu101:\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth>=1.4.1->google-api-python-client==1.8.0->cloud-tpu-client) (4.1.1)\n",
            "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /usr/local/lib/python3.6/dist-packages (from google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client) (2.23.0)\n",
            "Requirement already satisfied: protobuf>=3.4.0 in /usr/local/lib/python3.6/dist-packages (from google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client) (3.12.4)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.6/dist-packages (from google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client) (2018.9)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client) (1.52.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client) (2020.6.20)\n",
            "Installing collected packages: google-api-python-client, cloud-tpu-client\n",
            "  Found existing installation: google-api-python-client 1.7.12\n",
            "    Uninstalling google-api-python-client-1.7.12:\n",
            "      Successfully uninstalled google-api-python-client-1.7.12\n",
            "Successfully installed cloud-tpu-client-0.10 google-api-python-client-1.8.0\n",
            "Done updating TPU runtime\n",
            "  Successfully uninstalled torch-1.6.0+cu101\n",
            "Uninstalling torchvision-0.7.0+cu101:\n",
            "  Successfully uninstalled torchvision-0.7.0+cu101\n",
            "Copying gs://tpu-pytorch/wheels/torch-nightly+20200516-cp36-cp36m-linux_x86_64.whl...\n",
            "- [1 files][ 91.0 MiB/ 91.0 MiB]                                                \n",
            "Operation completed over 1 objects/91.0 MiB.                                     \n",
            "Copying gs://tpu-pytorch/wheels/torch_xla-nightly+20200516-cp36-cp36m-linux_x86_64.whl...\n",
            "- [1 files][119.8 MiB/119.8 MiB]                                                \n",
            "Operation completed over 1 objects/119.8 MiB.                                    \n",
            "Copying gs://tpu-pytorch/wheels/torchvision-nightly+20200516-cp36-cp36m-linux_x86_64.whl...\n",
            "/ [1 files][  2.3 MiB/  2.3 MiB]                                                \n",
            "Operation completed over 1 objects/2.3 MiB.                                      \n",
            "Processing ./torch-nightly+20200516-cp36-cp36m-linux_x86_64.whl\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch==nightly+20200516) (1.18.5)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch==nightly+20200516) (0.16.0)\n",
            "\u001b[31mERROR: fastai 1.0.61 requires torchvision, which is not installed.\u001b[0m\n",
            "Installing collected packages: torch\n",
            "Successfully installed torch-1.6.0a0+83df3be\n",
            "Processing ./torch_xla-nightly+20200516-cp36-cp36m-linux_x86_64.whl\n",
            "Installing collected packages: torch-xla\n",
            "Successfully installed torch-xla-1.6+2191422\n",
            "Processing ./torchvision-nightly+20200516-cp36-cp36m-linux_x86_64.whl\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision==nightly+20200516) (7.0.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchvision==nightly+20200516) (1.18.5)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from torchvision==nightly+20200516) (1.6.0a0+83df3be)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch->torchvision==nightly+20200516) (0.16.0)\n",
            "Installing collected packages: torchvision\n",
            "Successfully installed torchvision-0.7.0a0+348dd5a\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following NEW packages will be installed:\n",
            "  libomp5\n",
            "0 upgraded, 1 newly installed, 0 to remove and 11 not upgraded.\n",
            "Need to get 234 kB of archives.\n",
            "After this operation, 774 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libomp5 amd64 5.0.1-1 [234 kB]\n",
            "Fetched 234 kB in 1s (360 kB/s)\n",
            "Selecting previously unselected package libomp5:amd64.\n",
            "(Reading database ... 144599 files and directories currently installed.)\n",
            "Preparing to unpack .../libomp5_5.0.1-1_amd64.deb ...\n",
            "Unpacking libomp5:amd64 (5.0.1-1) ...\n",
            "Setting up libomp5:amd64 (5.0.1-1) ...\n",
            "Processing triggers for libc-bin (2.27-3ubuntu1.2) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/python3.6/dist-packages/ideep4py/lib/libmkldnn.so.0 is not a symbolic link\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "doL9jmdMNUdh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from matplotlib import pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import time\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torch_xla\n",
        "import torch_xla.core.xla_model as xm\n",
        "import torch_xla.debug.metrics as met\n",
        "import torch_xla.distributed.parallel_loader as pl\n",
        "import torch_xla.distributed.xla_multiprocessing as xmp\n",
        "import torch_xla.utils.utils as u\n",
        "import torchvision\n",
        "from torchvision import datasets,transforms\n",
        "import time\n",
        "from google.colab.patches import cv2_imshow\n",
        "import cv2"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tqaV0sP1QjuC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define Parameters\n",
        "FLAGS = {}\n",
        "FLAGS['data_dir'] = \"/tmp/cifar\"\n",
        "FLAGS['batch_size'] = 128\n",
        "FLAGS['num_workers'] = 4\n",
        "FLAGS['learning_rate'] = 0.02\n",
        "FLAGS['momentum'] = 0.9\n",
        "FLAGS['num_epochs'] = 50\n",
        "FLAGS['num_cores'] = 8\n",
        "FLAGS['log_steps'] = 20\n",
        "FLAGS['metrics_debug'] = False"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dzgDbWHYQjw2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class BasicBlock(nn.Module):\n",
        "  expansion = 1\n",
        "\n",
        "  def __init__(self, in_planes, planes, stride=1):\n",
        "    super(BasicBlock, self).__init__()\n",
        "    self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
        "    self.bn1 = nn.BatchNorm2d(planes)\n",
        "    self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "    self.bn2 = nn.BatchNorm2d(planes)\n",
        "\n",
        "    self.shortcut = nn.Sequential()\n",
        "    if stride != 1 or in_planes != self.expansion * planes:\n",
        "      self.shortcut = nn.Sequential(\n",
        "          nn.Conv2d(\n",
        "              in_planes,\n",
        "              self.expansion * planes,\n",
        "              kernel_size=1,\n",
        "              stride=stride,\n",
        "              bias=False), nn.BatchNorm2d(self.expansion * planes))\n",
        "    \n",
        "  def forward(self, x):\n",
        "    out = F.relu(self.bn1(self.conv1(x)))\n",
        "    out = self.bn2(self.conv2(out))\n",
        "    out += self.shortcut(x)\n",
        "    out = F.relu(out)\n",
        "    return out\n",
        "\n",
        "\n",
        "class ResNet(nn.Module):\n",
        "  def __init__(self, block, num_blocks, num_classes=10):\n",
        "    super(ResNet, self).__init__()\n",
        "    self.in_planes = 64\n",
        "\n",
        "    self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "    self.bn1 = nn.BatchNorm2d(64)\n",
        "    self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n",
        "    self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n",
        "    self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n",
        "    self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n",
        "    self.linear = nn.Linear(512 * block.expansion, num_classes)\n",
        "\n",
        "  def _make_layer(self, block, planes, num_blocks, stride):\n",
        "    strides = [stride] + [1] * (num_blocks - 1)\n",
        "    layers = []\n",
        "    for stride in strides:\n",
        "      layers.append(block(self.in_planes, planes, stride))\n",
        "      self.in_planes = planes * block.expansion\n",
        "    return nn.Sequential(*layers)\n",
        "\n",
        "  def forward(self, x):\n",
        "    out = F.relu(self.bn1(self.conv1(x)))\n",
        "    out = self.layer1(out)\n",
        "    out = self.layer2(out)\n",
        "    out = self.layer3(out)\n",
        "    out = self.layer4(out)\n",
        "    out = F.avg_pool2d(out, 4)\n",
        "    out = torch.flatten(out, 1)\n",
        "    out = self.linear(out)\n",
        "    return F.log_softmax(out, dim=1)\n",
        "\n",
        "  def ResNet50():\n",
        "    return ResNet(BasicBlock, [3, 4, 6, 4, 3])\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BCszdC0XQjzk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 229
        },
        "outputId": "37e17fc9-508e-40f1-9559-324737a2b7ad"
      },
      "source": [
        "SERIAL_EXEC = xmp.MpSerialExecutor()\n",
        "# Only instantiate model weights once in memory.\n",
        "WRAPPED_MODEL = xmp.MpModelWrapper(ResNet50())\n",
        "\n",
        "def train_resnet50():\n",
        "  torch.manual_seed(1)\n",
        "\n",
        "  def get_dataset():\n",
        "    norm = transforms.Normalize(\n",
        "        mean=(0.4914, 0.4822, 0.4465), std=(0.2023, 0.1994, 0.2010))\n",
        "    transform_train = transforms.Compose([\n",
        "        transforms.RandomCrop(32, padding=4),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.ToTensor(),\n",
        "        norm,\n",
        "    ])\n",
        "    transform_test = transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        norm,\n",
        "    ])\n",
        "    train_dataset = datasets.CIFAR10(\n",
        "        root=FLAGS['data_dir'],\n",
        "        train=True,\n",
        "        download=True,\n",
        "        transform=transform_train)\n",
        "    test_dataset = datasets.CIFAR10(\n",
        "        root=FLAGS['data_dir'],\n",
        "        train=False,\n",
        "        download=True,\n",
        "        transform=transform_test)\n",
        "   \n",
        "    return train_dataset, test_dataset\n",
        " \n",
        "  # Using the serial executor avoids multiple processes\n",
        "  # to download the same data.\n",
        "  train_dataset, test_dataset = SERIAL_EXEC.run(get_dataset)\n",
        "\n",
        "  train_sampler = torch.utils.data.distributed.DistributedSampler(\n",
        "      train_dataset,\n",
        "      num_replicas=xm.xrt_world_size(),\n",
        "      rank=xm.get_ordinal(),\n",
        "      shuffle=True)\n",
        "  train_loader = torch.utils.data.DataLoader(\n",
        "      train_dataset,\n",
        "      batch_size=FLAGS['batch_size'],\n",
        "      sampler=train_sampler,\n",
        "      num_workers=FLAGS['num_workers'],\n",
        "      drop_last=True)\n",
        "  test_loader = torch.utils.data.DataLoader(\n",
        "      test_dataset,\n",
        "      batch_size=FLAGS['batch_size'],\n",
        "      shuffle=False,\n",
        "      num_workers=FLAGS['num_workers'],\n",
        "      drop_last=True)\n",
        "\n",
        "  # Scale learning rate to num cores\n",
        "  learning_rate = FLAGS['learning_rate'] * xm.xrt_world_size()\n",
        "\n",
        "  # Get loss function, optimizer, and model\n",
        "  device = xm.xla_device()\n",
        "  model = WRAPPED_MODEL.to(device)\n",
        "  optimizer = optim.SGD(model.parameters(), lr=learning_rate,\n",
        "                        momentum=FLAGS['momentum'], weight_decay=5e-4)\n",
        "  loss_fn = nn.NLLLoss()\n",
        "\n",
        "  def train_loop_fn(loader):\n",
        "    tracker = xm.RateTracker()\n",
        "    model.train()\n",
        "    for x, (data, target) in enumerate(loader):\n",
        "      optimizer.zero_grad()\n",
        "      output = model(data)\n",
        "      loss = loss_fn(output, target)\n",
        "      loss.backward()\n",
        "      xm.optimizer_step(optimizer)\n",
        "      tracker.add(FLAGS['batch_size'])\n",
        "      if x % FLAGS['log_steps'] == 0:\n",
        "        print('[xla:{}]({}) Loss={:.2f} Time={}'.format(xm.get_ordinal(), x, loss.item(), time.asctime()), flush=True)\n",
        "\n",
        "  def test_loop_fn(loader):\n",
        "    total_samples = 0\n",
        "    correct = 0\n",
        "    model.eval()\n",
        "    data, pred, target = None, None, None\n",
        "    for data, target in loader:\n",
        "      output = model(data)\n",
        "      pred = output.max(1, keepdim=True)[1]\n",
        "      correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "      total_samples += data.size()[0]\n",
        "\n",
        "    accuracy = 100.0 * correct / total_samples\n",
        "    print('[xla:{}] Accuracy={:.2f}%'.format(\n",
        "        xm.get_ordinal(), accuracy), flush=True)\n",
        "    return accuracy, data, pred, target\n",
        "\n",
        "  # Train and eval loops\n",
        "  accuracy = 0.0\n",
        "  data, pred, target = None, None, None\n",
        "  for epoch in range(1, FLAGS['num_epochs'] + 1):\n",
        "    para_loader = pl.ParallelLoader(train_loader, [device])\n",
        "    train_loop_fn(para_loader.per_device_loader(device))\n",
        "    xm.master_print(\"Finished training epoch {}\".format(epoch))\n",
        "\n",
        "    para_loader = pl.ParallelLoader(test_loader, [device])\n",
        "    accuracy, data, pred, target  = test_loop_fn(para_loader.per_device_loader(device))\n",
        "    if FLAGS['metrics_debug']:\n",
        "      xm.master_print(met.metrics_report(), flush=True)\n",
        "\n",
        "  return accuracy, data, pred, target"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-23dfb1257bd0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mSERIAL_EXEC\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxmp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMpSerialExecutor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# Only instantiate model weights once in memory.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mWRAPPED_MODEL\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxmp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMpModelWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mResNet50\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtrain_resnet50\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'ResNet50' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-LPyTkMvQj2c",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 454
        },
        "outputId": "ab50823c-943d-4442-987a-4a9f3f85a60b"
      },
      "source": [
        "start_time = time.time()\n",
        "# Start training processes\n",
        "def training(rank, flags):\n",
        "  global FLAGS\n",
        "  FLAGS = flags\n",
        "  torch.set_default_tensor_type('torch.FloatTensor')\n",
        "  accuracy, data, pred, target = train_resnet50()\n",
        "  if rank == 0:\n",
        "    # Retrieve tensors that are on TPU core 0 and plot.\n",
        "    plot_results(data.cpu(), pred.cpu(), target.cpu())\n",
        "\n",
        "xmp.spawn(training, args=(FLAGS,), nprocs=FLAGS['num_cores'],\n",
        "          start_method='fork')"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Exception in device=TPU:0: name 'train_resnet50' is not defined\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch_xla/distributed/xla_multiprocessing.py\", line 231, in _start_fn\n",
            "    fn(gindex, *args)\n",
            "  File \"<ipython-input-12-e1fda48eca0b>\", line 7, in training\n",
            "    accuracy, data, pred, target = train_resnet50()\n",
            "NameError: name 'train_resnet50' is not defined\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "Exception",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-e1fda48eca0b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m xmp.spawn(training, args=(FLAGS,), nprocs=FLAGS['num_cores'],\n\u001b[0;32m---> 13\u001b[0;31m           start_method='fork')\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch_xla/distributed/xla_multiprocessing.py\u001b[0m in \u001b[0;36mspawn\u001b[0;34m(fn, args, nprocs, join, daemon, start_method)\u001b[0m\n\u001b[1;32m    294\u001b[0m         \u001b[0mjoin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m         \u001b[0mdaemon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdaemon\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m         start_method=start_method)\n\u001b[0m\u001b[1;32m    297\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/multiprocessing/spawn.py\u001b[0m in \u001b[0;36mstart_processes\u001b[0;34m(fn, args, nprocs, join, daemon, start_method)\u001b[0m\n\u001b[1;32m    156\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m     \u001b[0;31m# Loop on join until it returns True or raises an exception.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 158\u001b[0;31m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    159\u001b[0m         \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/multiprocessing/spawn.py\u001b[0m in \u001b[0;36mjoin\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    111\u001b[0m                 raise Exception(\n\u001b[1;32m    112\u001b[0m                     \u001b[0;34m\"process %d terminated with exit code %d\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m                     \u001b[0;34m(\u001b[0m\u001b[0merror_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexitcode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m                 )\n\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mException\u001b[0m: process 0 terminated with exit code 17"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IWx37MxsQj7K",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "3940ed3a-09a4-4496-fb1c-fa28894d451b"
      },
      "source": [
        "end_time = time.time()\n",
        "print(\"Time taken = \", end_time-start_time)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Time taken =  20.818894863128662\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FYCBnY0kQj-N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "img = cv2.imread(RESULT_IMG_PATH, cv2.IMREAD_UNCHANGED)\n",
        "cv2_imshow(img"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N-LPOrXbQkBF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A1B1k5bnQkD4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uh9CtIIYQkGh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EuScqlRZQkJu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dwkaldo9QkMG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F0UOBUhFQkPM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XKEW3N4yQkRx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GnPYAdD4QkUJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "61Gofsw4QkXF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lwl6_S39QkaE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QzJBu7n6Qkc-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5u_AqlDbCguP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}